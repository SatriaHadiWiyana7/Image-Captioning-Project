{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cf83e1cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "IMAGE CAPTIONING - TEXT PREPROCESSING\n",
      "======================================================================\n",
      "\n",
      "Loading Dataset\n",
      "Total rows loaded: 40455\n",
      "Columns: ['image', 'caption']\n",
      "\n",
      "First 5 rows:\n",
      "                       image  \\\n",
      "0  1000268201_693b08cb0e.jpg   \n",
      "1  1000268201_693b08cb0e.jpg   \n",
      "2  1000268201_693b08cb0e.jpg   \n",
      "3  1000268201_693b08cb0e.jpg   \n",
      "4  1000268201_693b08cb0e.jpg   \n",
      "\n",
      "                                             caption  \n",
      "0  Seorang anak dengan gaun merah muda sedang men...  \n",
      "1       Seorang gadis pergi ke sebuah bangunan kayu.  \n",
      "2  Seorang gadis kecil memanjat ke sebuah rumah b...  \n",
      "3  Seorang gadis kecil menaiki tangga ke rumah be...  \n",
      "4  Seorang gadis kecil dengan gaun merah muda mas...  \n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# LOAD DATA\n",
    "# ============================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import pickle\n",
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"IMAGE CAPTIONING - TEXT PREPROCESSING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nLoading Dataset\")\n",
    "\n",
    "CAPTION_FILE = r'D:\\CODE\\Image-Captioning-Project\\data\\captions.txt'\n",
    "OUTPUT_DIR = r'D:\\CODE\\Image-Captioning-Project\\features\\text_preprocessing'\n",
    "\n",
    "df = pd.read_csv(CAPTION_FILE, sep=',')\n",
    "print(f\"Total rows loaded: {len(df)}\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")\n",
    "\n",
    "print(f\"\\nFirst 5 rows:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "36ffe5dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "Text Preprocessing\n",
      "\n",
      "Preprocessing completed!\n",
      "Sample preprocessed captions:\n",
      "\n",
      "Original  : Seorang anak dengan gaun merah muda sedang menaiki seperangkat tangga dengan jalan masuk.\n",
      "Processed : startseq seorang anak dengan gaun merah muda sedang menaiki seperangkat tangga dengan jalan masuk endseq\n",
      "\n",
      "Original  : Seorang gadis pergi ke sebuah bangunan kayu.\n",
      "Processed : startseq seorang gadis pergi ke sebuah bangunan kayu endseq\n",
      "\n",
      "Original  : Seorang gadis kecil memanjat ke sebuah rumah bermain kayu.\n",
      "Processed : startseq seorang gadis kecil memanjat ke sebuah rumah bermain kayu endseq\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# TEXT PREPROCESSING FUNCTION\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Text Preprocessing\")\n",
    "\n",
    "def preprocess_caption(caption):\n",
    "    \"\"\"\n",
    "    Preprocessing caption text:\n",
    "    - Lowercase semua huruf\n",
    "    - Hapus karakter khusus (angka, tanda baca)\n",
    "    - Hapus extra spaces\n",
    "    - Tambahkan start dan end tokens\n",
    "    \"\"\"\n",
    "    # Convert to string\n",
    "    caption = str(caption)\n",
    "\n",
    "    # Convert to lowercase\n",
    "    caption = caption.lower()\n",
    "\n",
    "    # Remove special characters and numbers, keep only letters\n",
    "    caption = re.sub(r'[^a-z\\s]', '', caption)\n",
    "\n",
    "    # Remove multiple spaces\n",
    "    caption = re.sub(r'\\s+', ' ', caption)\n",
    "\n",
    "    # Strip whitespace\n",
    "    caption = caption.strip()\n",
    "\n",
    "    # Add start and end sequence tokens\n",
    "    caption = 'startseq ' + caption + ' endseq'\n",
    "\n",
    "    return caption\n",
    "\n",
    "# Apply preprocessing\n",
    "df['caption_clean'] = df['caption'].apply(preprocess_caption)\n",
    "\n",
    "print(\"\\nPreprocessing completed!\")\n",
    "print(f\"Sample preprocessed captions:\")\n",
    "for i in range(min(3, len(df))):\n",
    "    print(f\"\\nOriginal  : {df['caption'].iloc[i]}\")\n",
    "    print(f\"Processed : {df['caption_clean'].iloc[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d9dac4e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "Building Vocabulary\n",
      "\n",
      "Total words (with repetition): 450153\n",
      "Unique words: 7238\n",
      "\n",
      "Vocabulary size after filtering (freq >= 5): 2564\n",
      "Final vocabulary size: 2566\n",
      "\n",
      "Top 20 most common words:\n",
      "  startseq: 40455 times\n",
      "  endseq: 40455 times\n",
      "  di: 27859 times\n",
      "  seorang: 16308 times\n",
      "  dengan: 10992 times\n",
      "  anjing: 10221 times\n",
      "  dan: 8721 times\n",
      "  pria: 7388 times\n",
      "  anak: 6887 times\n",
      "  dua: 5573 times\n",
      "  seekor: 5233 times\n",
      "  wanita: 4410 times\n",
      "  hitam: 4124 times\n",
      "  orang: 4025 times\n",
      "  gadis: 3979 times\n",
      "  putih: 3901 times\n",
      "  yang: 3562 times\n",
      "  bermain: 3450 times\n",
      "  merah: 3378 times\n",
      "  berjalan: 3349 times\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# BUILD VOCABULARY\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Building Vocabulary\")\n",
    "\n",
    "# Collect all words from all captions\n",
    "all_captions = df['caption_clean'].tolist()\n",
    "all_words = []\n",
    "\n",
    "for caption in all_captions:\n",
    "    all_words.extend(caption.split())\n",
    "\n",
    "# Count word frequencies\n",
    "word_counts = Counter(all_words)\n",
    "\n",
    "print(f\"\\nTotal words (with repetition): {len(all_words)}\")\n",
    "print(f\"Unique words: {len(word_counts)}\")\n",
    "\n",
    "# Filter words by minimum frequency\n",
    "MIN_WORD_FREQ = 5\n",
    "\n",
    "vocab = [word for word, count in word_counts.items() if count >= MIN_WORD_FREQ]\n",
    "vocab = sorted(vocab)\n",
    "\n",
    "print(f\"\\nVocabulary size after filtering (freq >= {MIN_WORD_FREQ}): {len(vocab)}\")\n",
    "\n",
    "# Create word to index mapping\n",
    "word_to_idx = {}\n",
    "word_to_idx['<PAD>'] = 0  # Padding token\n",
    "idx = 1\n",
    "\n",
    "for word in vocab:\n",
    "    word_to_idx[word] = idx\n",
    "    idx += 1\n",
    "\n",
    "word_to_idx['<UNK>'] = idx  # Unknown token\n",
    "\n",
    "# Create index to word mapping\n",
    "idx_to_word = {idx: word for word, idx in word_to_idx.items()}\n",
    "\n",
    "vocab_size = len(word_to_idx)\n",
    "print(f\"Final vocabulary size: {vocab_size}\")\n",
    "print(f\"\\nTop 20 most common words:\")\n",
    "for word, count in word_counts.most_common(20):\n",
    "    print(f\"  {word}: {count} times\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5d155982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "Converting Captions to Sequences\n",
      "\n",
      "Max caption length: 32 tokens\n",
      "\n",
      "Sample sequences:\n",
      "\n",
      "Caption: startseq seorang anak dengan gaun merah muda sedang menaiki seperangkat tangga dengan jalan masuk endseq\n",
      "Sequence: [2274, 2159, 35, 545, 712, 1587, 1640, 2100, 1388, 2565, 2326, 545, 873, 1270, 670]\n",
      "\n",
      "Caption: startseq seorang gadis pergi ke sebuah bangunan kayu endseq\n",
      "Sequence: [2274, 2159, 699, 1851, 987, 2097, 134, 986, 670]\n",
      "\n",
      "Caption: startseq seorang gadis kecil memanjat ke sebuah rumah bermain kayu endseq\n",
      "Sequence: [2274, 2159, 699, 994, 1327, 987, 2097, 2041, 304, 986, 670]\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CONVERT CAPTIONS TO SEQUENCES\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Converting Captions to Sequences\")\n",
    "\n",
    "def caption_to_sequence(caption, word_to_idx):\n",
    "    \"\"\"Convert caption text to sequence of word indices\"\"\"\n",
    "    words = caption.split()\n",
    "    sequence = []\n",
    "\n",
    "    for word in words:\n",
    "        if word in word_to_idx:\n",
    "            sequence.append(word_to_idx[word])\n",
    "        else:\n",
    "            sequence.append(word_to_idx['<UNK>'])\n",
    "\n",
    "    return sequence\n",
    "\n",
    "# Apply conversion\n",
    "df['caption_seq'] = df['caption_clean'].apply(\n",
    "    lambda x: caption_to_sequence(x, word_to_idx)\n",
    ")\n",
    "\n",
    "# Calculate max caption length\n",
    "max_length = max(len(seq) for seq in df['caption_seq'])\n",
    "\n",
    "print(f\"\\nMax caption length: {max_length} tokens\")\n",
    "print(f\"\\nSample sequences:\")\n",
    "for i in range(min(3, len(df))):\n",
    "    print(f\"\\nCaption: {df['caption_clean'].iloc[i]}\")\n",
    "    print(f\"Sequence: {df['caption_seq'].iloc[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "278898e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STEP 5: Creating Image-to-Captions Mapping\n",
      "\n",
      "Total unique images: 8091\n",
      "Average captions per image: 5.00\n",
      "\n",
      "Sample - Image: 1000268201_693b08cb0e.jpg\n",
      "  Caption 1: startseq seorang anak dengan gaun merah muda sedang menaiki seperangkat tangga dengan jalan masuk endseq\n",
      "  Caption 2: startseq seorang gadis pergi ke sebuah bangunan kayu endseq\n",
      "  Caption 3: startseq seorang gadis kecil memanjat ke sebuah rumah bermain kayu endseq\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CREATE IMAGE-TO-CAPTIONS MAPPING\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 5: Creating Image-to-Captions Mapping\")\n",
    "\n",
    "# Group captions by image\n",
    "image_to_captions = {}\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    image_name = row['image']\n",
    "    caption_clean = row['caption_clean']\n",
    "\n",
    "    if image_name not in image_to_captions:\n",
    "        image_to_captions[image_name] = []\n",
    "\n",
    "    image_to_captions[image_name].append(caption_clean)\n",
    "\n",
    "print(f\"\\nTotal unique images: {len(image_to_captions)}\")\n",
    "print(f\"Average captions per image: {len(df) / len(image_to_captions):.2f}\")\n",
    "\n",
    "# Sample mapping\n",
    "sample_image = list(image_to_captions.keys())[0]\n",
    "print(f\"\\nSample - Image: {sample_image}\")\n",
    "for i, cap in enumerate(image_to_captions[sample_image][:3], 1):\n",
    "    print(f\"  Caption {i}: {cap}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c27184bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "Saving Preprocessing Artifacts\n",
      "Save location: D:\\CODE\\Image-Captioning-Project\\features\\text_preprocessing\n",
      "Saved: D:\\CODE\\Image-Captioning-Project\\features\\text_preprocessing\\captions_preprocessed.csv\n",
      "Saved: D:\\CODE\\Image-Captioning-Project\\features\\text_preprocessing\\word_to_idx.pkl\n",
      "Saved: D:\\CODE\\Image-Captioning-Project\\features\\text_preprocessing\\idx_to_word.pkl\n",
      "Saved: D:\\CODE\\Image-Captioning-Project\\features\\text_preprocessing\\image_to_captions.pkl\n",
      "Saved: D:\\CODE\\Image-Captioning-Project\\features\\text_preprocessing\\preprocessing_config.pkl\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# SAVE PREPROCESSING ARTIFACTS\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Saving Preprocessing Artifacts\")\n",
    "print(f\"Save location: {OUTPUT_DIR}\")\n",
    "\n",
    "# Save preprocessed dataframe\n",
    "output_file = os.path.join(OUTPUT_DIR, 'captions_preprocessed.csv')\n",
    "df.to_csv(output_file, index=False)\n",
    "print(f\"Saved: {output_file}\")\n",
    "\n",
    "# Save vocabulary mappings\n",
    "with open(os.path.join(OUTPUT_DIR, 'word_to_idx.pkl'), 'wb') as f:\n",
    "    pickle.dump(word_to_idx, f)\n",
    "print(f\"Saved: {os.path.join(OUTPUT_DIR, 'word_to_idx.pkl')}\")\n",
    "\n",
    "with open(os.path.join(OUTPUT_DIR, 'idx_to_word.pkl'), 'wb') as f:\n",
    "    pickle.dump(idx_to_word, f)\n",
    "print(f\"Saved: {os.path.join(OUTPUT_DIR, 'idx_to_word.pkl')}\")\n",
    "\n",
    "# Save image-to-captions mapping\n",
    "with open(os.path.join(OUTPUT_DIR, 'image_to_captions.pkl'), 'wb') as f:\n",
    "    pickle.dump(image_to_captions, f)\n",
    "print(f\"Saved: {os.path.join(OUTPUT_DIR, 'image_to_captions.pkl')}\")\n",
    "\n",
    "# Save preprocessing config\n",
    "preprocessing_config = {\n",
    "    'vocab_size': vocab_size,\n",
    "    'max_length': max_length,\n",
    "    'min_word_freq': MIN_WORD_FREQ,\n",
    "    'total_images': len(image_to_captions),\n",
    "    'total_captions': len(df)\n",
    "}\n",
    "\n",
    "with open(os.path.join(OUTPUT_DIR, 'preprocessing_config.pkl'), 'wb') as f:\n",
    "    pickle.dump(preprocessing_config, f)\n",
    "print(f\"Saved: {os.path.join(OUTPUT_DIR, 'preprocessing_config.pkl')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2a43ef0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "PREPROCESSING SUMMARY\n",
      "======================================================================\n",
      "Total images: 8091\n",
      "Total captions: 40455\n",
      "Vocabulary size: 2566\n",
      "Max caption length: 32 tokens\n",
      "Min word frequency: 5\n",
      "Special tokens: <PAD> (0), <UNK> (2565)\n",
      "Sequence tokens: startseq, endseq\n",
      "\n",
      "======================================================================\n",
      "PREPROCESSING COMPLETED SUCCESSFULLY!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# SUMMARY\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PREPROCESSING SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Total images: {preprocessing_config['total_images']}\")\n",
    "print(f\"Total captions: {preprocessing_config['total_captions']}\")\n",
    "print(f\"Vocabulary size: {preprocessing_config['vocab_size']}\")\n",
    "print(f\"Max caption length: {preprocessing_config['max_length']} tokens\")\n",
    "print(f\"Min word frequency: {preprocessing_config['min_word_freq']}\")\n",
    "print(f\"Special tokens: <PAD> (0), <UNK> ({word_to_idx['<UNK>']})\") \n",
    "print(f\"Sequence tokens: startseq, endseq\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PREPROCESSING COMPLETED SUCCESSFULLY!\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
